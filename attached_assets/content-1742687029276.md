[Skip to content](https://github.com/aigc3d/LHM#start-of-content)

You signed in with another tab or window. [Reload](https://github.com/aigc3d/LHM) to refresh your session.You signed out in another tab or window. [Reload](https://github.com/aigc3d/LHM) to refresh your session.You switched accounts on another tab or window. [Reload](https://github.com/aigc3d/LHM) to refresh your session.Dismiss alert

[aigc3d](https://github.com/aigc3d)/ **[LHM](https://github.com/aigc3d/LHM)** Public

- [Notifications](https://github.com/login?return_to=%2Faigc3d%2FLHM) You must be signed in to change notification settings
- [Fork\\
23](https://github.com/login?return_to=%2Faigc3d%2FLHM)
- [Star\\
480](https://github.com/login?return_to=%2Faigc3d%2FLHM)


Code of LHM: Large Animatable Human Reconstruction Model for Single Image to 3D in Seconds


[lingtengqiu.github.io/LHM/](https://lingtengqiu.github.io/LHM/ "https://lingtengqiu.github.io/LHM/")

### License

[Apache-2.0 license](https://github.com/aigc3d/LHM/blob/main/LICENSE)

[480\\
stars](https://github.com/aigc3d/LHM/stargazers) [23\\
forks](https://github.com/aigc3d/LHM/forks) [Branches](https://github.com/aigc3d/LHM/branches) [Tags](https://github.com/aigc3d/LHM/tags) [Activity](https://github.com/aigc3d/LHM/activity)

[Star](https://github.com/login?return_to=%2Faigc3d%2FLHM)

[Notifications](https://github.com/login?return_to=%2Faigc3d%2FLHM) You must be signed in to change notification settings

# aigc3d/LHM

main

[**1** Branch](https://github.com/aigc3d/LHM/branches) [**0** Tags](https://github.com/aigc3d/LHM/tags)

[Go to Branches page](https://github.com/aigc3d/LHM/branches)[Go to Tags page](https://github.com/aigc3d/LHM/tags)

Go to file

Code

## Folders and files

| Name | Name | Last commit message | Last commit date |
| --- | --- | --- | --- |
| ## Latest commit<br>![author](https://github.githubassets.com/images/gravatars/gravatar-user-420.png?size=40)<br>é¹¤ç¦¹<br>[LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf)<br>Mar 21, 2025<br>[c6909d1](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf)Â Â·Â Mar 21, 2025<br>## History<br>[17 Commits](https://github.com/aigc3d/LHM/commits/main/) |
| [LHM](https://github.com/aigc3d/LHM/tree/main/LHM "LHM") | [LHM](https://github.com/aigc3d/LHM/tree/main/LHM "LHM") | [LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf "LHM export mesh") | Mar 21, 2025 |
| [assets](https://github.com/aigc3d/LHM/tree/main/assets "assets") | [assets](https://github.com/aigc3d/LHM/tree/main/assets "assets") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [configs](https://github.com/aigc3d/LHM/tree/main/configs "configs") | [configs](https://github.com/aigc3d/LHM/tree/main/configs "configs") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [engine](https://github.com/aigc3d/LHM/tree/main/engine "engine") | [engine](https://github.com/aigc3d/LHM/tree/main/engine "engine") | [Update detector.py](https://github.com/aigc3d/LHM/commit/81d22a50ee78169a25ad8fd4d544849a372e20ac "Update detector.py") | Mar 20, 2025 |
| [scripts](https://github.com/aigc3d/LHM/tree/main/scripts "scripts") | [scripts](https://github.com/aigc3d/LHM/tree/main/scripts "scripts") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [tools/metrics](https://github.com/aigc3d/LHM/tree/main/tools/metrics "This path skips through empty directories") | [tools/metrics](https://github.com/aigc3d/LHM/tree/main/tools/metrics "This path skips through empty directories") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [train\_data](https://github.com/aigc3d/LHM/tree/main/train_data "train_data") | [train\_data](https://github.com/aigc3d/LHM/tree/main/train_data "train_data") | [add demo.mp4](https://github.com/aigc3d/LHM/commit/8af42787da2790985b9c512c0281c3a1107e602e "add demo.mp4") | Mar 20, 2025 |
| [.gitignore](https://github.com/aigc3d/LHM/blob/main/.gitignore ".gitignore") | [.gitignore](https://github.com/aigc3d/LHM/blob/main/.gitignore ".gitignore") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [.gitmodules](https://github.com/aigc3d/LHM/blob/main/.gitmodules ".gitmodules") | [.gitmodules](https://github.com/aigc3d/LHM/blob/main/.gitmodules ".gitmodules") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [INSTALL.md](https://github.com/aigc3d/LHM/blob/main/INSTALL.md "INSTALL.md") | [INSTALL.md](https://github.com/aigc3d/LHM/blob/main/INSTALL.md "INSTALL.md") | [update install guidance](https://github.com/aigc3d/LHM/commit/1595046472b70ce5f4aa1c09d10b7a41b5f4e180 "update install guidance") | Mar 17, 2025 |
| [LICENSE](https://github.com/aigc3d/LHM/blob/main/LICENSE "LICENSE") | [LICENSE](https://github.com/aigc3d/LHM/blob/main/LICENSE "LICENSE") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [README.md](https://github.com/aigc3d/LHM/blob/main/README.md "README.md") | [README.md](https://github.com/aigc3d/LHM/blob/main/README.md "README.md") | [LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf "LHM export mesh") | Mar 21, 2025 |
| [README\_CN.md](https://github.com/aigc3d/LHM/blob/main/README_CN.md "README_CN.md") | [README\_CN.md](https://github.com/aigc3d/LHM/blob/main/README_CN.md "README_CN.md") | [LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf "LHM export mesh") | Mar 21, 2025 |
| [app.py](https://github.com/aigc3d/LHM/blob/main/app.py "app.py") | [app.py](https://github.com/aigc3d/LHM/blob/main/app.py "app.py") | [auto download wegihts](https://github.com/aigc3d/LHM/commit/b879a590192356c95caab76fec16942badd71641 "auto download wegihts") | Mar 19, 2025 |
| [convert.sh](https://github.com/aigc3d/LHM/blob/main/convert.sh "convert.sh") | [convert.sh](https://github.com/aigc3d/LHM/blob/main/convert.sh "convert.sh") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [download\_weights.sh](https://github.com/aigc3d/LHM/blob/main/download_weights.sh "download_weights.sh") | [download\_weights.sh](https://github.com/aigc3d/LHM/blob/main/download_weights.sh "download_weights.sh") | [first commit](https://github.com/aigc3d/LHM/commit/5e2ed8b1283c0aac10bd18759d9dc0154cd848f0 "first commit") | Mar 13, 2025 |
| [inference.sh](https://github.com/aigc3d/LHM/blob/main/inference.sh "inference.sh") | [inference.sh](https://github.com/aigc3d/LHM/blob/main/inference.sh "inference.sh") | [LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf "LHM export mesh") | Mar 21, 2025 |
| [inference\_mesh.sh](https://github.com/aigc3d/LHM/blob/main/inference_mesh.sh "inference_mesh.sh") | [inference\_mesh.sh](https://github.com/aigc3d/LHM/blob/main/inference_mesh.sh "inference_mesh.sh") | [LHM export mesh](https://github.com/aigc3d/LHM/commit/c6909d1a7c87619c755e5899bc80fbed8d00f1cf "LHM export mesh") | Mar 21, 2025 |
| [install\_cu118.sh](https://github.com/aigc3d/LHM/blob/main/install_cu118.sh "install_cu118.sh") | [install\_cu118.sh](https://github.com/aigc3d/LHM/blob/main/install_cu118.sh "install_cu118.sh") | [update install guidance](https://github.com/aigc3d/LHM/commit/1595046472b70ce5f4aa1c09d10b7a41b5f4e180 "update install guidance") | Mar 17, 2025 |
| [install\_cu121.sh](https://github.com/aigc3d/LHM/blob/main/install_cu121.sh "install_cu121.sh") | [install\_cu121.sh](https://github.com/aigc3d/LHM/blob/main/install_cu121.sh "install_cu121.sh") | [update install guidance](https://github.com/aigc3d/LHM/commit/1595046472b70ce5f4aa1c09d10b7a41b5f4e180 "update install guidance") | Mar 17, 2025 |
| [requirements.txt](https://github.com/aigc3d/LHM/blob/main/requirements.txt "requirements.txt") | [requirements.txt](https://github.com/aigc3d/LHM/blob/main/requirements.txt "requirements.txt") | [update install guidance](https://github.com/aigc3d/LHM/commit/1595046472b70ce5f4aa1c09d10b7a41b5f4e180 "update install guidance") | Mar 17, 2025 |
| View all files |

## Repository files navigation

# [![](https://github.com/aigc3d/LHM/raw/main/assets/LHM_logo_parsing.png)](https://github.com/aigc3d/LHM/blob/main/assets/LHM_logo_parsing.png) \- Official PyTorch Implementation

[Permalink:  - Official PyTorch Implementation](https://github.com/aigc3d/LHM#---official-pytorch-implementation)

[![Project Website](https://camo.githubusercontent.com/1e7072b50bd9f4eb641e6ece4451d2091db4e48292b844ed2e16e8ebb2c812fa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462538432539302d50726f6a6563745f576562736974652d626c756576696f6c6574)](https://lingtengqiu.github.io/LHM/)[![arXiv Paper](https://camo.githubusercontent.com/2a6ef0f2ccfd48e29a74c2bd51a78d7adea9ff148e026995d6c8787398440b35/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462539332539432d61725869763a323530332d3130363235)](https://arxiv.org/pdf/2503.10625)[![HuggingFace](https://camo.githubusercontent.com/f3a32e5e482a8d2ca6061237baa0918faa95ce35f740b18eff74074625da4a89/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462541342539372d48756767696e67466163655f53706163652d626c7565)](https://huggingface.co/spaces/DyrusQZ/LHM)[![Apache License](https://camo.githubusercontent.com/dd0c01964f09e700a7f343bee0d77ca0da4acb493759a5b85f02b57f83a71b8a/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f2546302539462539332538332d4170616368652d2d322e302d393239323932)](https://www.apache.org/licenses/LICENSE-2.0)

[![](https://github.com/aigc3d/LHM/raw/main/assets/LHM_teaser.png)](https://github.com/aigc3d/LHM/blob/main/assets/LHM_teaser.png)

å¦‚æœæ‚¨ç†Ÿæ‚‰ä¸­æ–‡ï¼Œå¯ä»¥ [é˜…è¯»ä¸­æ–‡ç‰ˆæœ¬çš„README](https://github.com/aigc3d/LHM/blob/main/README_CN.md)

## ğŸ“¢ Latest Updates

[Permalink: ğŸ“¢ Latest Updates](https://github.com/aigc3d/LHM#-latest-updates)

**\[March 20, 2025\]** Release video motion processing pipeline

**\[March 19, 2025\]** Local Gradio App.py

**\[March 19, 2025\]** Gradio Optimization: Faster and More Stable ğŸ”¥ğŸ”¥ğŸ”¥

**\[March 15, 2025\]** Inference Time Optimization: 30% Faster

**\[March 13, 2025\]** Initial release with:

âœ… Inference codebase

âœ… Pretrained LHM-0.5B model

âœ… Pretrained LHM-1B model

âœ… Real-time rendering pipeline

âœ… Huggingface Online Demo

### TODO List

[Permalink: TODO List](https://github.com/aigc3d/LHM#todo-list)

- [x]  Core Inference Pipeline (v0.1) ğŸ”¥ğŸ”¥ğŸ”¥
- [x]  HuggingFace Demo Integration ğŸ¤—ğŸ¤—ğŸ¤—
- [ ]  ModelScope Deployment
- [x]  Motion Processing Scripts
- [ ]  Training Codes Release

## ğŸš€ Getting Started

[Permalink: ğŸš€ Getting Started](https://github.com/aigc3d/LHM#-getting-started)

### Environment Setup

[Permalink: Environment Setup](https://github.com/aigc3d/LHM#environment-setup)

Clone the repository.

```
git clone git@github.com:aigc3d/LHM.git
cd LHM
```

Install dependencies by script.

```
# cuda 11.8
sh ./install_cu118.sh

# cuda 12.1
sh ./install_cu121.sh

```

The installation has been tested with python3.10, CUDA 11.8 or CUDA 12.1.

Or you can install dependencies step by step, following [INSTALL.md](https://github.com/aigc3d/LHM/blob/main/INSTALL.md).

### Model Weights

[Permalink: Model Weights](https://github.com/aigc3d/LHM#model-weights)

Please note that the model will be downloaded automatically if you do not download it yourself.

| Model | Training Data | BH-T Layers | Link | Inference Time |
| :-- | :-- | :-- | :-- | :-- |
| LHM-0.5B | 5K Synthetic Data | 5 | OSS | 2.01 s |
| LHM-0.5B | 300K Videos + 5K Synthetic Data | 5 | [OSS](https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-0.5B.tar) | 2.01 s |
| LHM-0.7B | 300K Videos + 5K Synthetic Data | 10 | OSS | 4.13 s |
| LHM-1.0B | 300K Videos + 5K Synthetic Data | 15 | [OSS](https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-1B.tar) | 6.57 s |

```
# Download prior model weights
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-0.5B.tar
tar -xvf LHM-0.5B.tar
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM-1B.tar
tar -xvf LHM-1B.tar
```

### Download Prior Model Weights

[Permalink: Download Prior Model Weights](https://github.com/aigc3d/LHM#download-prior-model-weights)

```
# Download prior model weights
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/LHM_prior_model.tar
tar -xvf LHM_prior_model.tar
```

### Data Motion Preparation

[Permalink: Data Motion Preparation](https://github.com/aigc3d/LHM#data-motion-preparation)

We provide the test motion examples, we will update the processing scripts ASAP :).

```
# Download prior model weights
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/motion_video.tar
tar -xvf ./motion_video.tar
```

After downloading weights and data, the folder of the project structure seems like:

```
â”œâ”€â”€ configs
â”‚   â”œâ”€â”€ inference
â”‚   â”œâ”€â”€ accelerate-train-1gpu.yaml
â”‚   â”œâ”€â”€ accelerate-train-deepspeed.yaml
â”‚   â”œâ”€â”€ accelerate-train.yaml
â”‚   â””â”€â”€ infer-gradio.yaml
â”œâ”€â”€ engine
â”‚   â”œâ”€â”€ BiRefNet
â”‚   â”œâ”€â”€ pose_estimation
â”‚   â”œâ”€â”€ SegmentAPI
â”œâ”€â”€ example_data
â”‚   â””â”€â”€ test_data
â”œâ”€â”€ exps
â”‚   â”œâ”€â”€ releases
â”œâ”€â”€ LHM
â”‚   â”œâ”€â”€ datasets
â”‚   â”œâ”€â”€ losses
â”‚   â”œâ”€â”€ models
â”‚   â”œâ”€â”€ outputs
â”‚   â”œâ”€â”€ runners
â”‚   â”œâ”€â”€ utils
â”‚   â”œâ”€â”€ launch.py
â”œâ”€â”€ pretrained_models
â”‚   â”œâ”€â”€ dense_sample_points
â”‚   â”œâ”€â”€ gagatracker
â”‚   â”œâ”€â”€ human_model_files
â”‚   â”œâ”€â”€ sam2
â”‚   â”œâ”€â”€ sapiens
â”‚   â”œâ”€â”€ voxel_grid
â”‚   â”œâ”€â”€ arcface_resnet18.pth
â”‚   â”œâ”€â”€ BiRefNet-general-epoch_244.pth
â”œâ”€â”€ scripts
â”‚   â”œâ”€â”€ exp
â”‚   â”œâ”€â”€ convert_hf.py
â”‚   â””â”€â”€ upload_hub.py
â”œâ”€â”€ tools
â”‚   â”œâ”€â”€ metrics
â”œâ”€â”€ train_data
â”‚   â”œâ”€â”€ example_imgs
â”‚   â”œâ”€â”€ motion_video
â”œâ”€â”€ inference.sh
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
```

### ğŸ’» Local Gradio Run

[Permalink: ğŸ’» Local Gradio Run](https://github.com/aigc3d/LHM#-local-gradio-run)

```
python ./app.py
```

### ğŸƒ Inference Pipeline

[Permalink: ğŸƒ Inference Pipeline](https://github.com/aigc3d/LHM#-inference-pipeline)

```
# MODEL_NAME: {LHM-500M, LHM-1B}
# bash ./inference.sh ./configs/inference/human-lrm-500M.yaml LHM-500M ./train_data/example_imgs/ ./train_data/motion_video/mimo1/smplx_params
# bash ./inference.sh ./configs/inference/human-lrm-1B.yaml LHM-1B ./exps/releases/video_human_benchmark/human-lrm-1B/step_060000/ ./train_data/example_imgs/ ./train_data/motion_video/mimo1/smplx_params

# animation
bash inference.sh ${CONFIG} ${MODEL_NAME} ${IMAGE_PATH_OR_FOLDER}  ${MOTION_SEQ}

# export mesh
bash ./inference_mesh.sh ${CONFIG} ${MODEL_NAME}
```

### Custom Video Motion Processing

[Permalink: Custom Video Motion Processing](https://github.com/aigc3d/LHM#custom-video-motion-processing)

- Download model weights for motion processing.



```
wget -P ./pretrained_models/human_model_files/pose_estimate https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/yolov8x.pt

wget -P ./pretrained_models/human_model_files/pose_estimate https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/LHM/vitpose-h-wholebody.pth
```

- Install extra dependencies.



```
cd ./engine/pose_estimation
pip install -v -e third-party/ViTPose
pip install ultralytics
```

- Run the script.



```
# python ./engine/pose_estimation/video2motion.py --video_path ./train_data/demo.mp4 --output_path ./train_data/custom_motion

python ./engine/pose_estimation/video2motion.py --video_path ${VIDEO_PATH} --output_path ${OUTPUT_PATH}

```

- Use the motion to drive avatar.



```
# bash ./inference.sh ./configs/inference/human-lrm-500M.yaml LHM-500M ./train_data/example_imgs/ ./train_data/custom_motion/demo/smplx_params

bash inference.sh ${CONFIG} ${MODEL_NAME} ${IMAGE_PATH_OR_FOLDER}  ${OUTPUT_PATH}/${VIDEO_NAME}/smplx_params
```


## Compute Metric

[Permalink: Compute Metric](https://github.com/aigc3d/LHM#compute-metric)

We provide some simple script to compute the metrics.

```
# download pretrain model into ./pretrained_models/
wget https://virutalbuy-public.oss-cn-hangzhou.aliyuncs.com/share/aigc3d/data/for_lingteng/arcface_resnet18.pth
# Face Similarity
python ./tools/metrics/compute_facesimilarity.py -f1 ${gt_folder} -f2 ${results_folder}
# PSNR
python ./tools/metrics/compute_psnr.py -f1 ${gt_folder} -f2 ${results_folder}
# SSIM LPIPS
python ./tools/metrics/compute_ssim_lpips.py -f1 ${gt_folder} -f2 ${results_folder}
```

## Acknowledgement

[Permalink: Acknowledgement](https://github.com/aigc3d/LHM#acknowledgement)

This work is built on many amazing research works and open-source projects:

- [OpenLRM](https://github.com/3DTopia/OpenLRM)
- [ExAvatar](https://github.com/mks0601/ExAvatar_RELEASE)
- [DreamGaussian](https://github.com/dreamgaussian/dreamgaussian)

Thanks for their excellent works and great contribution to 3D generation and 3D digital human area.

## Citation

[Permalink: Citation](https://github.com/aigc3d/LHM#citation)

```
@inproceedings{qiu2025LHM,
  title={LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds},
  author={Lingteng Qiu and Xiaodong Gu and Peihao Li  and Qi Zuo
     and Weichao Shen and Junfei Zhang and Kejie Qiu and Weihao Yuan
     and Guanying Chen and Zilong Dong and Liefeng Bo
    },
  booktitle={arXiv preprint arXiv:2503.10625},
  year={2025}
}

```

## About

Code of LHM: Large Animatable Human Reconstruction Model for Single Image to 3D in Seconds


[lingtengqiu.github.io/LHM/](https://lingtengqiu.github.io/LHM/ "https://lingtengqiu.github.io/LHM/")

### Topics

[aigc](https://github.com/topics/aigc "Topic: aigc") [digitalhuman](https://github.com/topics/digitalhuman "Topic: digitalhuman") [aicg](https://github.com/topics/aicg "Topic: aicg")

### Resources

[Readme](https://github.com/aigc3d/LHM#readme-ov-file)

### License

[Apache-2.0 license](https://github.com/aigc3d/LHM#Apache-2.0-1-ov-file)

[Activity](https://github.com/aigc3d/LHM/activity)

[Custom properties](https://github.com/aigc3d/LHM/custom-properties)

### Stars

[**480**\\
stars](https://github.com/aigc3d/LHM/stargazers)

### Watchers

[**10**\\
watching](https://github.com/aigc3d/LHM/watchers)

### Forks

[**23**\\
forks](https://github.com/aigc3d/LHM/forks)

[Report repository](https://github.com/contact/report-content?content_url=https%3A%2F%2Fgithub.com%2Faigc3d%2FLHM&report=aigc3d+%28user%29)

## [Releases](https://github.com/aigc3d/LHM/releases)

No releases published

## [Packages\  0](https://github.com/orgs/aigc3d/packages?repo_name=LHM)

No packages published

## [Contributors\  4](https://github.com/aigc3d/LHM/graphs/contributors)

- [![@lingtengqiu](https://avatars.githubusercontent.com/u/37240099?s=64&v=4)](https://github.com/lingtengqiu)[**lingtengqiu** Lingteng Qiu (é‚±é™µè…¾ï¼‰](https://github.com/lingtengqiu)
- [![@liphao99](https://avatars.githubusercontent.com/u/34979027?s=64&v=4)](https://github.com/liphao99)[**liphao99** PEIHAO LI](https://github.com/liphao99)
- [![@hitsz-zuoqi](https://avatars.githubusercontent.com/u/58206232?s=64&v=4)](https://github.com/hitsz-zuoqi)[**hitsz-zuoqi** QiZuo](https://github.com/hitsz-zuoqi)
- [![@eltociear](https://avatars.githubusercontent.com/u/22633385?s=64&v=4)](https://github.com/eltociear)[**eltociear** Ikko Eltociear Ashimine](https://github.com/eltociear)

## Languages

- [Python59.1%](https://github.com/aigc3d/LHM/search?l=python)
- [Jupyter Notebook40.6%](https://github.com/aigc3d/LHM/search?l=jupyter-notebook)
- [Shell0.3%](https://github.com/aigc3d/LHM/search?l=shell)

You canâ€™t perform that action at this time.